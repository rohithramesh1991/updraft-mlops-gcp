name: Production Deploy

on:
  push:
    branches: [ main ]

jobs:
  build-push-deploy:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        component: [load_data, preprocess, train, evaluate]
    steps:
      - uses: actions/checkout@v2

      - name: Install dependencies
        run: |
          pip install pytest pandas scikit-learn xgboost joblib google-cloud-bigquery kfp

      - name: Authenticate Docker to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Configure Docker for Artifact Registry
        run: |
          gcloud auth configure-docker ${{ secrets.GCP_REGION }}-docker.pkg.dev --quiet

      - name: Build Docker image
        run: |
          cd components/${{ matrix.component }}
          docker build -t ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GCP_ARTIFACT_REPO }}/${{ matrix.component }}:${{ github.sha }} .

      - name: Push Docker image
        run: |
          docker push ${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GCP_ARTIFACT_REPO }}/${{ matrix.component }}:${{ github.sha }}

  # Compile and deploy pipeline (after all images are pushed)
  deploy-pipeline:
    runs-on: ubuntu-latest
    needs: build-push-deploy
    steps:
      - uses: actions/checkout@v2

      - name: Install dependencies
        run: pip install kfp google-cloud-aiplatform
      
      - name: Replace image URIs in pipeline
        run: |
          sed -i "s|{{LOAD_IMAGE_URI}}|${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GCP_ARTIFACT_REPO }}/load_data:${{ github.sha }}|g" pipelines/classification_pipeline.py
          sed -i "s|{{PREPROCESS_IMAGE_URI}}|${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GCP_ARTIFACT_REPO }}/preprocess:${{ github.sha }}|g" pipelines/classification_pipeline.py
          sed -i "s|{{TRAIN_IMAGE_URI}}|${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GCP_ARTIFACT_REPO }}/train:${{ github.sha }}|g" pipelines/classification_pipeline.py
          sed -i "s|{{EVALUATE_IMAGE_URI}}|${{ secrets.GCP_REGION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT_ID }}/${{ secrets.GCP_ARTIFACT_REPO }}/evaluate:${{ github.sha }}|g" pipelines/classification_pipeline.py

      - name: Create pipelines folder
        run: mkdir -p pipelines

      - name: Compile pipeline
        run: |
          python pipelines/compile_pipeline.py
      
      - name: Set up GCP credentials
        run: |
          echo "${{ secrets.GCP_SA_KEY }}" > ${HOME}/gcp-sa-key.json
        shell: bash

      - name: Deploy pipeline
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ HOME }}/gcp-sa-key.json
          GCP_PROJECT: ${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION: ${{ secrets.GCP_REGION }}
          BQ_DATASET: ${{ secrets.BQ_DATASET }}
          BQ_TABLE: ${{ secrets.BQ_TABLE }}
          PIPELINE_ROOT: ${{ secrets.PIPELINE_ROOT }}
        run: python pipelines/run_pipeline.py
